"0",""
"0",""
"0","# validating reviewers #"
"0","statdf2 <- statdf %>% filter(Reviewer != ""GPT4-Turbo"")"
"0","val <- aov( data = statdf2, value ~ Reviewer*Criteria)"
"0","summary(val)"
"1","                 "
"1","   Df"
"1"," Sum Sq"
"1"," Mean Sq"
"1"," F value"
"1"," Pr(>F)"
"1","    "
"1","
Reviewer         "
"1","    3"
"1","   49.9"
"1","  16.623"
"1","   28.90"
"1"," <2e-16"
"1"," ***"
"1","
Criteria         "
"1","    2"
"1","   48.4"
"1","  24.221"
"1","   42.10"
"1"," <2e-16"
"1"," ***"
"1","
Reviewer:Criteria"
"1","    6"
"1","   57.8"
"1","   9.628"
"1","   16.74"
"1"," <2e-16"
"1"," ***"
"1","
Residuals        "
"1"," 3255"
"1"," 1872.5"
"1","   0.575"
"1","        "
"1","       "
"1","    "
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"0","valtt <- TukeyHSD(val)"
"0","valtt"
"1","  Tukey multiple comparisons of means
"
"1","    "
"1",""
"1","95"
"1",""
"1","% family-wise confidence level
"
"1","
Fit: "
"1",""
"1","aov(formula = value ~ Reviewer * Criteria, data = statdf2)"
"1",""
"1","

"
"1","$Reviewer
"
"1","     "
"1","        diff"
"1","         lwr"
"1","        upr"
"1","     p adj"
"1","
R2-R1"
"1","  0.01851852"
"1"," -0.08474737"
"1","  0.1217844"
"1"," 0.9674914"
"1","
R3-R1"
"1"," -0.23569024"
"1"," -0.32805405"
"1"," -0.1433264"
"1"," 0.0000000"
"1","
R4-R1"
"1","  0.07744108"
"1"," -0.01492274"
"1","  0.1698049"
"1"," 0.1362215"
"1","
R3-R2"
"1"," -0.25420875"
"1"," -0.35747464"
"1"," -0.1509429"
"1"," 0.0000000"
"1","
R4-R2"
"1","  0.05892256"
"1"," -0.04434333"
"1","  0.1621884"
"1"," 0.4579316"
"1","
R4-R3"
"1","  0.31313131"
"1","  0.22076750"
"1","  0.4054951"
"1"," 0.0000000"
"1","
"
"1","
"
"1","$Criteria
"
"1","                                                 "
"1","       diff"
"1","         lwr"
"1","       upr"
"1","     p adj"
"1","
Context to Question-AI Response to Human Response"
"1"," 0.07805326"
"1"," 0.001839357"
"1"," 0.1542672"
"1"," 0.0432654"
"1","
Response to Context-AI Response to Human Response"
"1"," 0.28833792"
"1"," 0.212124022"
"1"," 0.3645518"
"1"," 0.0000000"
"1","
Response to Context-Context to Question          "
"1"," 0.21028466"
"1"," 0.134070762"
"1"," 0.2864986"
"1"," 0.0000000"
"1","
"
"1","
"
"1","$`Reviewer:Criteria`
"
"1","                                                                 "
"1","        diff"
"1","         lwr"
"1","          upr"
"1","     p adj"
"1","
R2:AI Response to Human Response-R1:AI Response to Human Response"
"1"," -0.13299663"
"1"," -0.36057198"
"1","  0.094578711"
"1"," 0.7523840"
"1","
R3:AI Response to Human Response-R1:AI Response to Human Response"
"1"," -0.26599327"
"1"," -0.46954284"
"1"," -0.062443691"
"1"," 0.0011929"
"1","
R4:AI Response to Human Response-R1:AI Response to Human Response"
"1","  0.42760943"
"1","  0.22405985"
"1","  0.631159003"
"1"," 0.0000000"
"1","
R1:Context to Question-R1:AI Response to Human Response          "
"1","  0.15488215"
"1"," -0.04866742"
"1","  0.358431730"
"1"," 0.3474312"
"1","
R2:Context to Question-R1:AI Response to Human Response          "
"1","  0.27609428"
"1","  0.04851893"
"1","  0.503669620"
"1"," 0.0042490"
"1","
R3:Context to Question-R1:AI Response to Human Response          "
"1"," -0.08754209"
"1"," -0.29109166"
"1","  0.116007488"
"1"," 0.9624999"
"1","
R4:Context to Question-R1:AI Response to Human Response          "
"1","  0.10774411"
"1"," -0.09580547"
"1","  0.311293683"
"1"," 0.8539288"
"1","
R1:Response to Context-R1:AI Response to Human Response          "
"1","  0.39057239"
"1","  0.18702282"
"1","  0.594121966"
"1"," 0.0000000"
"1","
R2:Response to Context-R1:AI Response to Human Response          "
"1","  0.45791246"
"1","  0.23033711"
"1","  0.685487802"
"1"," 0.0000000"
"1","
R3:Response to Context-R1:AI Response to Human Response          "
"1","  0.19191919"
"1"," -0.01163038"
"1","  0.395468767"
"1"," 0.0865944"
"1","
R4:Response to Context-R1:AI Response to Human Response          "
"1","  0.24242424"
"1","  0.03887467"
"1","  0.445973818"
"1"," 0.0056528"
"1","
R3:AI Response to Human Response-R2:AI Response to Human Response"
"1"," -0.13299663"
"1"," -0.36057198"
"1","  0.094578711"
"1"," 0.7523840"
"1","
R4:AI Response to Human Response-R2:AI Response to Human Response"
"1","  0.56060606"
"1","  0.33303072"
"1","  0.788181404"
"1"," 0.0000000"
"1","
R1:Context to Question-R2:AI Response to Human Response          "
"1","  0.28787879"
"1","  0.06030344"
"1","  0.515454132"
"1"," 0.0021320"
"1","
R2:Context to Question-R2:AI Response to Human Response          "
"1","  0.40909091"
"1","  0.15979461"
"1","  0.658387208"
"1"," 0.0000056"
"1","
R3:Context to Question-R2:AI Response to Human Response          "
"1","  0.04545455"
"1"," -0.18212080"
"1","  0.273029889"
"1"," 0.9999622"
"1","
R4:Context to Question-R2:AI Response to Human Response          "
"1","  0.24074074"
"1","  0.01316540"
"1","  0.468316084"
"1"," 0.0272700"
"1","
R1:Response to Context-R2:AI Response to Human Response          "
"1","  0.52356902"
"1","  0.29599368"
"1","  0.751144367"
"1"," 0.0000000"
"1","
R2:Response to Context-R2:AI Response to Human Response          "
"1","  0.59090909"
"1","  0.34161279"
"1","  0.840205390"
"1"," 0.0000000"
"1","
R3:Response to Context-R2:AI Response to Human Response          "
"1","  0.32491582"
"1","  0.09734048"
"1","  0.552491169"
"1"," 0.0001978"
"1","
R4:Response to Context-R2:AI Response to Human Response          "
"1","  0.37542088"
"1","  0.14784553"
"1","  0.602996219"
"1"," 0.0000048"
"1","
R4:AI Response to Human Response-R3:AI Response to Human Response"
"1","  0.69360269"
"1","  0.49005312"
"1","  0.897152269"
"1"," 0.0000000"
"1","
R1:Context to Question-R3:AI Response to Human Response          "
"1","  0.42087542"
"1","  0.21732585"
"1","  0.624424996"
"1"," 0.0000000"
"1","
R2:Context to Question-R3:AI Response to Human Response          "
"1","  0.54208754"
"1","  0.31451220"
"1","  0.769662886"
"1"," 0.0000000"
"1","
R3:Context to Question-R3:AI Response to Human Response          "
"1","  0.17845118"
"1"," -0.02509840"
"1","  0.382000754"
"1"," 0.1532610"
"1","
R4:Context to Question-R3:AI Response to Human Response          "
"1","  0.37373737"
"1","  0.17018780"
"1","  0.577286949"
"1"," 0.0000001"
"1","
R1:Response to Context-R3:AI Response to Human Response          "
"1","  0.65656566"
"1","  0.45301608"
"1","  0.860115232"
"1"," 0.0000000"
"1","
R2:Response to Context-R3:AI Response to Human Response          "
"1","  0.72390572"
"1","  0.49633038"
"1","  0.951481068"
"1"," 0.0000000"
"1","
R3:Response to Context-R3:AI Response to Human Response          "
"1","  0.45791246"
"1","  0.25436288"
"1","  0.661462033"
"1"," 0.0000000"
"1","
R4:Response to Context-R3:AI Response to Human Response          "
"1","  0.50841751"
"1","  0.30486793"
"1","  0.711967084"
"1"," 0.0000000"
"1","
R1:Context to Question-R4:AI Response to Human Response          "
"1"," -0.27272727"
"1"," -0.47627685"
"1"," -0.069177697"
"1"," 0.0007422"
"1","
R2:Context to Question-R4:AI Response to Human Response          "
"1"," -0.15151515"
"1"," -0.37909050"
"1","  0.076060192"
"1"," 0.5663364"
"1","
R3:Context to Question-R4:AI Response to Human Response          "
"1"," -0.51515152"
"1"," -0.71870109"
"1"," -0.311601940"
"1"," 0.0000000"
"1","
R4:Context to Question-R4:AI Response to Human Response          "
"1"," -0.31986532"
"1"," -0.52341490"
"1"," -0.116315744"
"1"," 0.0000189"
"1","
R1:Response to Context-R4:AI Response to Human Response          "
"1"," -0.03703704"
"1"," -0.24058661"
"1","  0.166512538"
"1"," 0.9999854"
"1","
R2:Response to Context-R4:AI Response to Human Response          "
"1","  0.03030303"
"1"," -0.19727231"
"1","  0.257878374"
"1"," 0.9999994"
"1","
R3:Response to Context-R4:AI Response to Human Response          "
"1"," -0.23569024"
"1"," -0.43923981"
"1"," -0.032140660"
"1"," 0.0085459"
"1","
R4:Response to Context-R4:AI Response to Human Response          "
"1"," -0.18518519"
"1"," -0.38873476"
"1","  0.018364390"
"1"," 0.1162411"
"1","
R2:Context to Question-R1:Context to Question                    "
"1","  0.12121212"
"1"," -0.10636322"
"1","  0.348787465"
"1"," 0.8486390"
"1","
R3:Context to Question-R1:Context to Question                    "
"1"," -0.24242424"
"1"," -0.44597382"
"1"," -0.038874667"
"1"," 0.0056528"
"1","
R4:Context to Question-R1:Context to Question                    "
"1"," -0.04713805"
"1"," -0.25068762"
"1","  0.156411528"
"1"," 0.9998346"
"1","
R1:Response to Context-R1:Context to Question                    "
"1","  0.23569024"
"1","  0.03214066"
"1","  0.439239811"
"1"," 0.0085459"
"1","
R2:Response to Context-R1:Context to Question                    "
"1","  0.30303030"
"1","  0.07545496"
"1","  0.530605647"
"1"," 0.0008370"
"1","
R3:Response to Context-R1:Context to Question                    "
"1","  0.03703704"
"1"," -0.16651254"
"1","  0.240586612"
"1"," 0.9999854"
"1","
R4:Response to Context-R1:Context to Question                    "
"1","  0.08754209"
"1"," -0.11600749"
"1","  0.291091663"
"1"," 0.9624999"
"1","
R3:Context to Question-R2:Context to Question                    "
"1"," -0.36363636"
"1"," -0.59121171"
"1"," -0.136061020"
"1"," 0.0000119"
"1","
R4:Context to Question-R2:Context to Question                    "
"1"," -0.16835017"
"1"," -0.39592551"
"1","  0.059225175"
"1"," 0.3930226"
"1","
R1:Response to Context-R2:Context to Question                    "
"1","  0.11447811"
"1"," -0.11309723"
"1","  0.342053458"
"1"," 0.8921807"
"1","
R2:Response to Context-R2:Context to Question                    "
"1","  0.18181818"
"1"," -0.06747812"
"1","  0.431114480"
"1"," 0.4163821"
"1","
R3:Response to Context-R2:Context to Question                    "
"1"," -0.08417508"
"1"," -0.31175043"
"1","  0.143400260"
"1"," 0.9883127"
"1","
R4:Response to Context-R2:Context to Question                    "
"1"," -0.03367003"
"1"," -0.26124538"
"1","  0.193905310"
"1"," 0.9999983"
"1","
R4:Context to Question-R3:Context to Question                    "
"1","  0.19528620"
"1"," -0.00826338"
"1","  0.398835771"
"1"," 0.0742514"
"1","
R1:Response to Context-R3:Context to Question                    "
"1","  0.47811448"
"1","  0.27456490"
"1","  0.681664054"
"1"," 0.0000000"
"1","
R2:Response to Context-R3:Context to Question                    "
"1","  0.54545455"
"1","  0.31787920"
"1","  0.773029889"
"1"," 0.0000000"
"1","
R3:Response to Context-R3:Context to Question                    "
"1","  0.27946128"
"1","  0.07591170"
"1","  0.483010855"
"1"," 0.0004559"
"1","
R4:Response to Context-R3:Context to Question                    "
"1","  0.32996633"
"1","  0.12641675"
"1","  0.533515905"
"1"," 0.0000080"
"1","
R1:Response to Context-R4:Context to Question                    "
"1","  0.28282828"
"1","  0.07927871"
"1","  0.486377858"
"1"," 0.0003556"
"1","
R2:Response to Context-R4:Context to Question                    "
"1","  0.35016835"
"1","  0.12259301"
"1","  0.577743694"
"1"," 0.0000329"
"1","
R3:Response to Context-R4:Context to Question                    "
"1","  0.08417508"
"1"," -0.11937449"
"1","  0.287724660"
"1"," 0.9719510"
"1","
R4:Response to Context-R4:Context to Question                    "
"1","  0.13468013"
"1"," -0.06886944"
"1","  0.338229710"
"1"," 0.5762362"
"1","
R2:Response to Context-R1:Response to Context                    "
"1","  0.06734007"
"1"," -0.16023528"
"1","  0.294915411"
"1"," 0.9983076"
"1","
R3:Response to Context-R1:Response to Context                    "
"1"," -0.19865320"
"1"," -0.40220277"
"1","  0.004896377"
"1"," 0.0633956"
"1","
R4:Response to Context-R1:Response to Context                    "
"1"," -0.14814815"
"1"," -0.35169772"
"1","  0.055401427"
"1"," 0.4197885"
"1","
R3:Response to Context-R2:Response to Context                    "
"1"," -0.26599327"
"1"," -0.49356861"
"1"," -0.038417922"
"1"," 0.0074685"
"1","
R4:Response to Context-R2:Response to Context                    "
"1"," -0.21548822"
"1"," -0.44306356"
"1","  0.012087128"
"1"," 0.0834470"
"1","
R4:Response to Context-R3:Response to Context                    "
"1","  0.05050505"
"1"," -0.15304452"
"1","  0.254054626"
"1"," 0.9996763"
"1","
"
"1","
"
"0","df_validate_stats <- df_validate_stats %>% mutate(Criteria = case_match(Criteria, 'Crit1' ~ 'Context to Question',"
"0","                                                                        'Crit2' ~ 'Response to Context',"
"0","                                                                        'Crit3' ~ 'AI Response to Human Response'))"
"0","valplot <- {ggplot(df_validate_stats, aes(x = Reviewer, y = mean, fill = Criteria, group = Criteria)) +"
"0","    geom_hline(yintercept = 2,linetype = 'dashed',alpha = 0.5 ) +"
"0","    geom_col(stat = ""identity"", position = ""dodge"", color = ""black"") +"
"0","    geom_errorbar(aes(ymin = mean - standard_error, ymax = mean + standard_error),"
"0","                  position = position_dodge(width = 0.9), width = 0.25) +"
"0","    labs(x = ""Reviewer"", y = ""Mean Assessed Quality"") +"
"0","    theme_classic() +"
"0","    coord_cartesian(ylim = c(1, 3)) +"
"0","    theme(legend.position = 'bottom') +"
"0","    #facet_wrap(~Question) +"
"0","    scale_fill_manual(values = crit_pal)} #will need to run process_evaluations_new before to get objects"
"2","Warning: [38;5;253mIgnoring unknown parameters: `stat`[39m"
"0","df_val <- df_validate %>% filter(Criteria != ""Crit4"") %>% mutate(Criteria = case_match(Criteria, 'Crit1' ~ 'Context to Question',"
"0","                                                                                       'Crit2' ~ 'Response to Context',"
"0","                                                                                       'Crit3' ~ 'AI Response to Human Response'))"
"0","crit1_mean <- df_val %>% filter(Criteria == ""Context to Question"") # crit 1 - in red"
"0","crit1_mean <- mean(crit1_mean$value)"
"0","print(crit1_mean) #mean = 2.458"
"1","[1]"
"1"," 2.458333"
"1","
"
"0","crit2_mean <- df_val %>% filter(Criteria == ""Response to Context"") #crit 2 - in green"
"0","crit2_mean <- mean(crit2_mean$value)"
"0","print(crit2_mean) #mean = 2.533"
"1","[1]"
"1"," 2.533333"
"1","
"
"0","crit3_mean <- df_val %>% filter(Criteria == ""AI Response to Human Response"") #crit 3 - in blue"
"0","crit3_mean <- mean(crit3_mean$value)"
"0","print(crit3_mean) #mean = 2.242"
"1","[1]"
"1"," 2.241667"
"1","
"
"0","# attempting to create 5th ""reviewer"" which is all combined data - I think is valid (talk with Dave) but not best approach"
"0","df_val2 <- df_val %>% filter(Criteria != ""NA"") %>% mutate(Reviewer = ""R5"")"
"0","valbind <- rbind(df_val, df_val2)"
"0",""
"0","valbind_stats = valbind %>% "
"0","  group_by(Criteria, Reviewer) %>% "
"0","  summarise(mean = mean(value),"
"0","            standard_error = sd(value, na.rm = TRUE) / sqrt(n()),"
"0","            st_dev = sd(value))"
"2","`summarise()` has grouped output by 'Criteria'. You can override using the `.groups` argument."
"0","valplot2 <- {ggplot(valbind_stats, aes(x = Reviewer, y = mean, fill = Criteria, group = Criteria)) +"
"0","    geom_hline(yintercept = 2,linetype = 'dashed',alpha = 0.5 ) +"
"0","    geom_col(stat = ""identity"", position = ""dodge"", color = ""black"") +"
"0","    geom_errorbar(aes(ymin = mean - standard_error, ymax = mean + standard_error),"
"0","                  position = position_dodge(width = 0.9), width = 0.25) +"
"0","    labs(x = ""Reviewer"", y = ""Mean Assessed Quality"") +"
"0","    theme_classic() +"
"0","    coord_cartesian(ylim = c(1, 3)) +"
"0","    theme(legend.position = 'bottom') +"
"0","    #facet_wrap(~Question) +"
"0","    scale_fill_manual(values = crit_pal)} # compares individual reviewers (1-4) to the mean of all the values (R5)"
"2","Warning: [38;5;253mIgnoring unknown parameters: `stat`[39m"
"0","valaov <- aov(data = valbind, value ~ Reviewer*Criteria)"
"0","summary(valaov)"
"1","                 "
"1","  Df"
"1"," Sum Sq"
"1"," Mean Sq"
"1"," F value"
"1","   Pr(>F)"
"1","    "
"1","
Reviewer         "
"1","   4"
"1","  12.49"
"1","   3.122"
"1","   7.009"
"1"," 1.55e-05"
"1"," ***"
"1","
Criteria         "
"1","   2"
"1","  11.01"
"1","   5.506"
"1","  12.359"
"1"," 5.30e-06"
"1"," ***"
"1","
Reviewer:Criteria"
"1","   8"
"1","   4.76"
"1","   0.595"
"1","   1.336"
"1","    0.222"
"1","    "
"1","
Residuals        "
"1"," 705"
"1"," 314.05"
"1","   0.445"
"1","        "
"1","         "
"1","    "
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"0","val_hsd <- TukeyHSD(valaov)"
"0","val_hsd "
"1","  Tukey multiple comparisons of means
"
"1","    "
"1",""
"1","95"
"1",""
"1","% family-wise confidence level
"
"1","
Fit: "
"1",""
"1","aov(formula = value ~ Reviewer * Criteria, data = valbind)"
"1",""
"1","

"
"1","$Reviewer
"
"1","     "
"1","          diff"
"1","        lwr"
"1","        upr"
"1","     p adj"
"1","
R2-R1"
"1","  4.222222e-01"
"1","  0.1501200"
"1"," 0.69432449"
"1"," 0.0002410"
"1","
R3-R1"
"1","  4.444444e-01"
"1","  0.1723422"
"1"," 0.71654671"
"1"," 0.0000902"
"1","
R4-R1"
"1","  4.222222e-01"
"1","  0.1501200"
"1"," 0.69432449"
"1"," 0.0002410"
"1","
R5-R1"
"1","  3.222222e-01"
"1","  0.1071065"
"1"," 0.53733795"
"1"," 0.0004488"
"1","
R3-R2"
"1","  2.222222e-02"
"1"," -0.2498800"
"1"," 0.29432449"
"1"," 0.9994476"
"1","
R4-R2"
"1","  4.884981e-15"
"1"," -0.2721023"
"1"," 0.27210227"
"1"," 1.0000000"
"1","
R5-R2"
"1"," -1.000000e-01"
"1"," -0.3151157"
"1"," 0.11511573"
"1"," 0.7089551"
"1","
R4-R3"
"1"," -2.222222e-02"
"1"," -0.2943245"
"1"," 0.24988004"
"1"," 0.9994476"
"1","
R5-R3"
"1"," -1.222222e-01"
"1"," -0.3373380"
"1"," 0.09289351"
"1"," 0.5276997"
"1","
R5-R4"
"1"," -1.000000e-01"
"1"," -0.3151157"
"1"," 0.11511573"
"1"," 0.7089551"
"1","
"
"1","
"
"1","$Criteria
"
"1","                                                 "
"1","      diff"
"1","         lwr"
"1","       upr"
"1","     p adj"
"1","
Context to Question-AI Response to Human Response"
"1"," 0.2166667"
"1","  0.07356781"
"1"," 0.3597655"
"1"," 0.0011672"
"1","
Response to Context-AI Response to Human Response"
"1"," 0.2916667"
"1","  0.14856781"
"1"," 0.4347655"
"1"," 0.0000062"
"1","
Response to Context-Context to Question          "
"1"," 0.0750000"
"1"," -0.06809886"
"1"," 0.2180989"
"1"," 0.4352598"
"1","
"
"1","
"
"1","$`Reviewer:Criteria`
"
"1","                                                                 "
"1","          diff"
"1","          lwr"
"1","       upr"
"1","     p adj"
"1","
R2:AI Response to Human Response-R1:AI Response to Human Response"
"1","  2.666667e-01"
"1"," -0.319846062"
"1"," 0.8531794"
"1"," 0.9686288"
"1","
R3:AI Response to Human Response-R1:AI Response to Human Response"
"1","  1.666667e-01"
"1"," -0.419846062"
"1"," 0.7531794"
"1"," 0.9997487"
"1","
R4:AI Response to Human Response-R1:AI Response to Human Response"
"1","  5.333333e-01"
"1"," -0.053179396"
"1"," 1.1198461"
"1"," 0.1220598"
"1","
R5:AI Response to Human Response-R1:AI Response to Human Response"
"1","  2.416667e-01"
"1"," -0.222012359"
"1"," 0.7053457"
"1"," 0.9079140"
"1","
R1:Context to Question-R1:AI Response to Human Response          "
"1","  1.333333e-01"
"1"," -0.453179396"
"1"," 0.7198461"
"1"," 0.9999830"
"1","
R2:Context to Question-R1:AI Response to Human Response          "
"1","  6.666667e-01"
"1","  0.080153938"
"1"," 1.2531794"
"1"," 0.0101397"
"1","
R3:Context to Question-R1:AI Response to Human Response          "
"1","  6.000000e-01"
"1","  0.013487271"
"1"," 1.1865127"
"1"," 0.0390063"
"1","
R4:Context to Question-R1:AI Response to Human Response          "
"1","  4.333333e-01"
"1"," -0.153179396"
"1"," 1.0198461"
"1"," 0.4312155"
"1","
R5:Context to Question-R1:AI Response to Human Response          "
"1","  4.583333e-01"
"1"," -0.005345692"
"1"," 0.9220124"
"1"," 0.0564449"
"1","
R1:Response to Context-R1:AI Response to Human Response          "
"1","  1.333333e-01"
"1"," -0.453179396"
"1"," 0.7198461"
"1"," 0.9999830"
"1","
R2:Response to Context-R1:AI Response to Human Response          "
"1","  6.000000e-01"
"1","  0.013487271"
"1"," 1.1865127"
"1"," 0.0390063"
"1","
R3:Response to Context-R1:AI Response to Human Response          "
"1","  8.333333e-01"
"1","  0.246820604"
"1"," 1.4198461"
"1"," 0.0001624"
"1","
R4:Response to Context-R1:AI Response to Human Response          "
"1","  5.666667e-01"
"1"," -0.019846062"
"1"," 1.1531794"
"1"," 0.0709227"
"1","
R5:Response to Context-R1:AI Response to Human Response          "
"1","  5.333333e-01"
"1","  0.069654308"
"1"," 0.9970124"
"1"," 0.0085258"
"1","
R3:AI Response to Human Response-R2:AI Response to Human Response"
"1"," -1.000000e-01"
"1"," -0.686512729"
"1"," 0.4865127"
"1"," 0.9999996"
"1","
R4:AI Response to Human Response-R2:AI Response to Human Response"
"1","  2.666667e-01"
"1"," -0.319846062"
"1"," 0.8531794"
"1"," 0.9686288"
"1","
R5:AI Response to Human Response-R2:AI Response to Human Response"
"1"," -2.500000e-02"
"1"," -0.488679025"
"1"," 0.4386790"
"1"," 1.0000000"
"1","
R1:Context to Question-R2:AI Response to Human Response          "
"1"," -1.333333e-01"
"1"," -0.719846062"
"1"," 0.4531794"
"1"," 0.9999830"
"1","
R2:Context to Question-R2:AI Response to Human Response          "
"1","  4.000000e-01"
"1"," -0.186512729"
"1"," 0.9865127"
"1"," 0.5749838"
"1","
R3:Context to Question-R2:AI Response to Human Response          "
"1","  3.333333e-01"
"1"," -0.253179396"
"1"," 0.9198461"
"1"," 0.8350666"
"1","
R4:Context to Question-R2:AI Response to Human Response          "
"1","  1.666667e-01"
"1"," -0.419846062"
"1"," 0.7531794"
"1"," 0.9997487"
"1","
R5:Context to Question-R2:AI Response to Human Response          "
"1","  1.916667e-01"
"1"," -0.272012359"
"1"," 0.6553457"
"1"," 0.9866274"
"1","
R1:Response to Context-R2:AI Response to Human Response          "
"1"," -1.333333e-01"
"1"," -0.719846062"
"1"," 0.4531794"
"1"," 0.9999830"
"1","
R2:Response to Context-R2:AI Response to Human Response          "
"1","  3.333333e-01"
"1"," -0.253179396"
"1"," 0.9198461"
"1"," 0.8350666"
"1","
R3:Response to Context-R2:AI Response to Human Response          "
"1","  5.666667e-01"
"1"," -0.019846062"
"1"," 1.1531794"
"1"," 0.0709227"
"1","
R4:Response to Context-R2:AI Response to Human Response          "
"1","  3.000000e-01"
"1"," -0.286512729"
"1"," 0.8865127"
"1"," 0.9197061"
"1","
R5:Response to Context-R2:AI Response to Human Response          "
"1","  2.666667e-01"
"1"," -0.197012359"
"1"," 0.7303457"
"1"," 0.8225135"
"1","
R4:AI Response to Human Response-R3:AI Response to Human Response"
"1","  3.666667e-01"
"1"," -0.219846062"
"1"," 0.9531794"
"1"," 0.7159221"
"1","
R5:AI Response to Human Response-R3:AI Response to Human Response"
"1","  7.500000e-02"
"1"," -0.388679025"
"1"," 0.5386790"
"1"," 0.9999998"
"1","
R1:Context to Question-R3:AI Response to Human Response          "
"1"," -3.333333e-02"
"1"," -0.619846062"
"1"," 0.5531794"
"1"," 1.0000000"
"1","
R2:Context to Question-R3:AI Response to Human Response          "
"1","  5.000000e-01"
"1"," -0.086512729"
"1"," 1.0865127"
"1"," 0.1981022"
"1","
R3:Context to Question-R3:AI Response to Human Response          "
"1","  4.333333e-01"
"1"," -0.153179396"
"1"," 1.0198461"
"1"," 0.4312155"
"1","
R4:Context to Question-R3:AI Response to Human Response          "
"1","  2.666667e-01"
"1"," -0.319846062"
"1"," 0.8531794"
"1"," 0.9686288"
"1","
R5:Context to Question-R3:AI Response to Human Response          "
"1","  2.916667e-01"
"1"," -0.172012359"
"1"," 0.7553457"
"1"," 0.7068353"
"1","
R1:Response to Context-R3:AI Response to Human Response          "
"1"," -3.333333e-02"
"1"," -0.619846062"
"1"," 0.5531794"
"1"," 1.0000000"
"1","
R2:Response to Context-R3:AI Response to Human Response          "
"1","  4.333333e-01"
"1"," -0.153179396"
"1"," 1.0198461"
"1"," 0.4312155"
"1","
R3:Response to Context-R3:AI Response to Human Response          "
"1","  6.666667e-01"
"1","  0.080153938"
"1"," 1.2531794"
"1"," 0.0101397"
"1","
R4:Response to Context-R3:AI Response to Human Response          "
"1","  4.000000e-01"
"1"," -0.186512729"
"1"," 0.9865127"
"1"," 0.5749838"
"1","
R5:Response to Context-R3:AI Response to Human Response          "
"1","  3.666667e-01"
"1"," -0.097012359"
"1"," 0.8303457"
"1"," 0.3122692"
"1","
R5:AI Response to Human Response-R4:AI Response to Human Response"
"1"," -2.916667e-01"
"1"," -0.755345692"
"1"," 0.1720124"
"1"," 0.7068353"
"1","
R1:Context to Question-R4:AI Response to Human Response          "
"1"," -4.000000e-01"
"1"," -0.986512729"
"1"," 0.1865127"
"1"," 0.5749838"
"1","
R2:Context to Question-R4:AI Response to Human Response          "
"1","  1.333333e-01"
"1"," -0.453179396"
"1"," 0.7198461"
"1"," 0.9999830"
"1","
R3:Context to Question-R4:AI Response to Human Response          "
"1","  6.666667e-02"
"1"," -0.519846062"
"1"," 0.6531794"
"1"," 1.0000000"
"1","
R4:Context to Question-R4:AI Response to Human Response          "
"1"," -1.000000e-01"
"1"," -0.686512729"
"1"," 0.4865127"
"1"," 0.9999996"
"1","
R5:Context to Question-R4:AI Response to Human Response          "
"1"," -7.500000e-02"
"1"," -0.538679025"
"1"," 0.3886790"
"1"," 0.9999998"
"1","
R1:Response to Context-R4:AI Response to Human Response          "
"1"," -4.000000e-01"
"1"," -0.986512729"
"1"," 0.1865127"
"1"," 0.5749838"
"1","
R2:Response to Context-R4:AI Response to Human Response          "
"1","  6.666667e-02"
"1"," -0.519846062"
"1"," 0.6531794"
"1"," 1.0000000"
"1","
R3:Response to Context-R4:AI Response to Human Response          "
"1","  3.000000e-01"
"1"," -0.286512729"
"1"," 0.8865127"
"1"," 0.9197061"
"1","
R4:Response to Context-R4:AI Response to Human Response          "
"1","  3.333333e-02"
"1"," -0.553179396"
"1"," 0.6198461"
"1"," 1.0000000"
"1","
R5:Response to Context-R4:AI Response to Human Response          "
"1"," -1.154632e-14"
"1"," -0.463679025"
"1"," 0.4636790"
"1"," 1.0000000"
"1","
R1:Context to Question-R5:AI Response to Human Response          "
"1"," -1.083333e-01"
"1"," -0.572012359"
"1"," 0.3553457"
"1"," 0.9999761"
"1","
R2:Context to Question-R5:AI Response to Human Response          "
"1","  4.250000e-01"
"1"," -0.038679025"
"1"," 0.8886790"
"1"," 0.1142525"
"1","
R3:Context to Question-R5:AI Response to Human Response          "
"1","  3.583333e-01"
"1"," -0.105345692"
"1"," 0.8220124"
"1"," 0.3513878"
"1","
R4:Context to Question-R5:AI Response to Human Response          "
"1","  1.916667e-01"
"1"," -0.272012359"
"1"," 0.6553457"
"1"," 0.9866274"
"1","
R5:Context to Question-R5:AI Response to Human Response          "
"1","  2.166667e-01"
"1"," -0.076589698"
"1"," 0.5099230"
"1"," 0.4312155"
"1","
R1:Response to Context-R5:AI Response to Human Response          "
"1"," -1.083333e-01"
"1"," -0.572012359"
"1"," 0.3553457"
"1"," 0.9999761"
"1","
R2:Response to Context-R5:AI Response to Human Response          "
"1","  3.583333e-01"
"1"," -0.105345692"
"1"," 0.8220124"
"1"," 0.3513878"
"1","
R3:Response to Context-R5:AI Response to Human Response          "
"1","  5.916667e-01"
"1","  0.127987641"
"1"," 1.0553457"
"1"," 0.0015159"
"1","
R4:Response to Context-R5:AI Response to Human Response          "
"1","  3.250000e-01"
"1"," -0.138679025"
"1"," 0.7886790"
"1"," 0.5264791"
"1","
R5:Response to Context-R5:AI Response to Human Response          "
"1","  2.916667e-01"
"1"," -0.001589698"
"1"," 0.5849230"
"1"," 0.0529476"
"1","
R2:Context to Question-R1:Context to Question                    "
"1","  5.333333e-01"
"1"," -0.053179396"
"1"," 1.1198461"
"1"," 0.1220598"
"1","
R3:Context to Question-R1:Context to Question                    "
"1","  4.666667e-01"
"1"," -0.119846062"
"1"," 1.0531794"
"1"," 0.3020605"
"1","
R4:Context to Question-R1:Context to Question                    "
"1","  3.000000e-01"
"1"," -0.286512729"
"1"," 0.8865127"
"1"," 0.9197061"
"1","
R5:Context to Question-R1:Context to Question                    "
"1","  3.250000e-01"
"1"," -0.138679025"
"1"," 0.7886790"
"1"," 0.5264791"
"1","
R1:Response to Context-R1:Context to Question                    "
"1","  1.332268e-15"
"1"," -0.586512729"
"1"," 0.5865127"
"1"," 1.0000000"
"1","
R2:Response to Context-R1:Context to Question                    "
"1","  4.666667e-01"
"1"," -0.119846062"
"1"," 1.0531794"
"1"," 0.3020605"
"1","
R3:Response to Context-R1:Context to Question                    "
"1","  7.000000e-01"
"1","  0.113487271"
"1"," 1.2865127"
"1"," 0.0048201"
"1","
R4:Response to Context-R1:Context to Question                    "
"1","  4.333333e-01"
"1"," -0.153179396"
"1"," 1.0198461"
"1"," 0.4312155"
"1","
R5:Response to Context-R1:Context to Question                    "
"1","  4.000000e-01"
"1"," -0.063679025"
"1"," 0.8636790"
"1"," 0.1824743"
"1","
R3:Context to Question-R2:Context to Question                    "
"1"," -6.666667e-02"
"1"," -0.653179396"
"1"," 0.5198461"
"1"," 1.0000000"
"1","
R4:Context to Question-R2:Context to Question                    "
"1"," -2.333333e-01"
"1"," -0.819846062"
"1"," 0.3531794"
"1"," 0.9907057"
"1","
R5:Context to Question-R2:Context to Question                    "
"1"," -2.083333e-01"
"1"," -0.672012359"
"1"," 0.2553457"
"1"," 0.9716676"
"1","
R1:Response to Context-R2:Context to Question                    "
"1"," -5.333333e-01"
"1"," -1.119846062"
"1"," 0.0531794"
"1"," 0.1220598"
"1","
R2:Response to Context-R2:Context to Question                    "
"1"," -6.666667e-02"
"1"," -0.653179396"
"1"," 0.5198461"
"1"," 1.0000000"
"1","
R3:Response to Context-R2:Context to Question                    "
"1","  1.666667e-01"
"1"," -0.419846062"
"1"," 0.7531794"
"1"," 0.9997487"
"1","
R4:Response to Context-R2:Context to Question                    "
"1"," -1.000000e-01"
"1"," -0.686512729"
"1"," 0.4865127"
"1"," 0.9999996"
"1","
R5:Response to Context-R2:Context to Question                    "
"1"," -1.333333e-01"
"1"," -0.597012359"
"1"," 0.3303457"
"1"," 0.9997117"
"1","
R4:Context to Question-R3:Context to Question                    "
"1"," -1.666667e-01"
"1"," -0.753179396"
"1"," 0.4198461"
"1"," 0.9997487"
"1","
R5:Context to Question-R3:Context to Question                    "
"1"," -1.416667e-01"
"1"," -0.605345692"
"1"," 0.3220124"
"1"," 0.9994230"
"1","
R1:Response to Context-R3:Context to Question                    "
"1"," -4.666667e-01"
"1"," -1.053179396"
"1"," 0.1198461"
"1"," 0.3020605"
"1","
R2:Response to Context-R3:Context to Question                    "
"1"," -3.552714e-15"
"1"," -0.586512729"
"1"," 0.5865127"
"1"," 1.0000000"
"1","
R3:Response to Context-R3:Context to Question                    "
"1","  2.333333e-01"
"1"," -0.353179396"
"1"," 0.8198461"
"1"," 0.9907057"
"1","
R4:Response to Context-R3:Context to Question                    "
"1"," -3.333333e-02"
"1"," -0.619846062"
"1"," 0.5531794"
"1"," 1.0000000"
"1","
R5:Response to Context-R3:Context to Question                    "
"1"," -6.666667e-02"
"1"," -0.530345692"
"1"," 0.3970124"
"1"," 1.0000000"
"1","
R5:Context to Question-R4:Context to Question                    "
"1","  2.500000e-02"
"1"," -0.438679025"
"1"," 0.4886790"
"1"," 1.0000000"
"1","
R1:Response to Context-R4:Context to Question                    "
"1"," -3.000000e-01"
"1"," -0.886512729"
"1"," 0.2865127"
"1"," 0.9197061"
"1","
R2:Response to Context-R4:Context to Question                    "
"1","  1.666667e-01"
"1"," -0.419846062"
"1"," 0.7531794"
"1"," 0.9997487"
"1","
R3:Response to Context-R4:Context to Question                    "
"1","  4.000000e-01"
"1"," -0.186512729"
"1"," 0.9865127"
"1"," 0.5749838"
"1","
R4:Response to Context-R4:Context to Question                    "
"1","  1.333333e-01"
"1"," -0.453179396"
"1"," 0.7198461"
"1"," 0.9999830"
"1","
R5:Response to Context-R4:Context to Question                    "
"1","  1.000000e-01"
"1"," -0.363679025"
"1"," 0.5636790"
"1"," 0.9999912"
"1","
R1:Response to Context-R5:Context to Question                    "
"1"," -3.250000e-01"
"1"," -0.788679025"
"1"," 0.1386790"
"1"," 0.5264791"
"1","
R2:Response to Context-R5:Context to Question                    "
"1","  1.416667e-01"
"1"," -0.322012359"
"1"," 0.6053457"
"1"," 0.9994230"
"1","
R3:Response to Context-R5:Context to Question                    "
"1","  3.750000e-01"
"1"," -0.088679025"
"1"," 0.8386790"
"1"," 0.2756744"
"1","
R4:Response to Context-R5:Context to Question                    "
"1","  1.083333e-01"
"1"," -0.355345692"
"1"," 0.5720124"
"1"," 0.9999761"
"1","
R5:Response to Context-R5:Context to Question                    "
"1","  7.500000e-02"
"1"," -0.218256365"
"1"," 0.3682564"
"1"," 0.9999279"
"1","
R2:Response to Context-R1:Response to Context                    "
"1","  4.666667e-01"
"1"," -0.119846062"
"1"," 1.0531794"
"1"," 0.3020605"
"1","
R3:Response to Context-R1:Response to Context                    "
"1","  7.000000e-01"
"1","  0.113487271"
"1"," 1.2865127"
"1"," 0.0048201"
"1","
R4:Response to Context-R1:Response to Context                    "
"1","  4.333333e-01"
"1"," -0.153179396"
"1"," 1.0198461"
"1"," 0.4312155"
"1","
R5:Response to Context-R1:Response to Context                    "
"1","  4.000000e-01"
"1"," -0.063679025"
"1"," 0.8636790"
"1"," 0.1824743"
"1","
R3:Response to Context-R2:Response to Context                    "
"1","  2.333333e-01"
"1"," -0.353179396"
"1"," 0.8198461"
"1"," 0.9907057"
"1","
R4:Response to Context-R2:Response to Context                    "
"1"," -3.333333e-02"
"1"," -0.619846062"
"1"," 0.5531794"
"1"," 1.0000000"
"1","
R5:Response to Context-R2:Response to Context                    "
"1"," -6.666667e-02"
"1"," -0.530345692"
"1"," 0.3970124"
"1"," 1.0000000"
"1","
R4:Response to Context-R3:Response to Context                    "
"1"," -2.666667e-01"
"1"," -0.853179396"
"1"," 0.3198461"
"1"," 0.9686288"
"1","
R5:Response to Context-R3:Response to Context                    "
"1"," -3.000000e-01"
"1"," -0.763679025"
"1"," 0.1636790"
"1"," 0.6633715"
"1","
R5:Response to Context-R4:Response to Context                    "
"1"," -3.333333e-02"
"1"," -0.497012359"
"1"," 0.4303457"
"1"," 1.0000000"
"1","
"
"1","
"
"0","#only reviewer 1 is sig. diff. from ""reviewer 5"" (the average of all data) WHEN ALL CRITERIA COMBINED"
"0","#no interaction between reviewer*criteria (p = 0.222) - only sig. diff is R1 vs R3 response to context"
"0",""
"0","## LMM analysis ##"
"0","library(lme4)"
"0","lmm_model <- lmer(value ~ AI + (1|Reviewer), data = statdf)"
"0","summary(lmm_model)"
"1","Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
"
"1","Formula:"
"1"," "
"1","value ~ AI + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","statdf"
"1","
"
"1","
"
"1","REML criterion at convergence:"
"1"," "
"1","14979.2"
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","    Min "
"1","     1Q "
"1"," Median "
"1","     3Q "
"1","    Max "
"1","
"
"1","-2.4094 "
"1","-0.6451 "
"1"," 0.2230 "
"1"," 0.6953 "
"1"," 1.6306 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.0454  "
"1"," 0.2131  "
"1","
"
"1"," Residual"
"1","            "
"1"," 0.5772  "
"1"," 0.7598  "
"1","
"
"1","Number of obs: 6531, groups: "
"1"," "
"1","Reviewer, 5"
"1","
"
"1","
Fixed effects:
"
"1","           "
"1","   Estimate"
"1"," Std. Error"
"1","         df"
"1"," t value"
"1"," Pr(>|t|)"
"1","    "
"1","
(Intercept)"
"1","    2.51596"
"1","    0.09685"
"1","    4.19644"
"1","   25.98"
"1"," 8.53e-06"
"1"," ***"
"1","
AIGPT4x1   "
"1","   -0.47819"
"1","    0.02303"
"1"," 6524.03958"
"1","  -20.76"
"1","  < 2e-16"
"1"," ***"
"1","
AIGPT4x3   "
"1","   -0.33907"
"1","    0.02303"
"1"," 6524.03958"
"1","  -14.72"
"1","  < 2e-16"
"1"," ***"
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"1","
Correlation of Fixed Effects:
"
"1","        "
"1"," (Intr)"
"1"," AIGPT41"
"1","
AIGPT4x1"
"1"," -0.119"
"1","        "
"1","
AIGPT4x3"
"1"," -0.119"
"1","  0.500 "
"1","
"
"0","lmm_mod_anova <- anova(lmm_model)"
"0","#TukeyHSD(lmm_mod_anova)"
"0",""
"0","## GLMM analysis ##"
"0","library(lme4)"
"0","library(emmeans)"
"0",""
"0","statdfx <- statdf %>% filter(Agent == ""Human"")"
"0",""
"0","glmm_mod <- glmer(value ~ AI + (1|Reviewer), data = statdfx, family = poisson) #but is poisson legit? only one that works"
"0","summary(glmm_mod)"
"1","Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
"
"1"," Family:"
"1"," "
"1","poisson"
"1"," "
"1"," ( log )"
"1","
"
"1","Formula:"
"1"," "
"1","value ~ AI + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","statdfx"
"1","
"
"1","
"
"1","     AIC "
"1","     BIC "
"1","  logLik "
"1","deviance "
"1","df.resid "
"1","
"
"1","  9520.1 "
"1","  9544.5 "
"1"," -4756.1 "
"1","  9512.1 "
"1","    3263 "
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","     Min "
"1","      1Q "
"1","  Median "
"1","      3Q "
"1","     Max "
"1","
"
"1","-0.94252 "
"1","-0.30831 "
"1","-0.00875 "
"1"," 0.52795 "
"1"," 0.86284 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.002684"
"1"," 0.0518  "
"1","
"
"1","Number of obs: 3267, groups: "
"1"," "
"1","Reviewer, 4"
"1","
"
"1","
Fixed effects:
"
"1","           "
"1"," Estimate"
"1"," Std. Error"
"1"," z value"
"1"," Pr(>|z|)"
"1","    "
"1","
(Intercept)"
"1","  0.86645"
"1","    0.03256"
"1","  26.608"
"1","  < 2e-16"
"1"," ***"
"1","
AIGPT4x1   "
"1"," -0.18209"
"1","    0.02915"
"1","  -6.248"
"1"," 4.17e-10"
"1"," ***"
"1","
AIGPT4x3   "
"1"," -0.11576"
"1","    0.02863"
"1","  -4.043"
"1"," 5.28e-05"
"1"," ***"
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"1","
Correlation of Fixed Effects:
"
"1","        "
"1"," (Intr)"
"1"," AIGPT41"
"1","
AIGPT4x1"
"1"," -0.407"
"1","        "
"1","
AIGPT4x3"
"1"," -0.414"
"1","  0.463 "
"1","
"
"0","anova(glmm_mod)"
"1","Analysis of Variance Table"
"1","
"
"1","  "
"1"," npar"
"1"," Sum Sq"
"1"," Mean Sq"
"1"," F value"
"1","
AI"
"1","    2"
"1","  40.71"
"1","  20.355"
"1","  20.355"
"1","
"
"0","emm <- emmeans(glmm_mod, ~ AI)"
"0","contrasts <- pairs(emm, adjust = ""tukey"")"
"0","print(contrasts)"
"1",""
"1"," contrast       "
"1"," estimate"
"1","     SE"
"1","  df"
"1"," z.ratio"
"1"," p.value"
"1","
"
"1"," Elicit - GPT4x1"
"1","   0.1821"
"1"," 0.0291"
"1"," Inf"
"1","   6.248"
"1","  <.0001"
"1","
"
"1"," Elicit - GPT4x3"
"1","   0.1158"
"1"," 0.0286"
"1"," Inf"
"1","   4.043"
"1","  0.0002"
"1","
"
"1"," GPT4x1 - GPT4x3"
"1","  -0.0663"
"1"," 0.0299"
"1"," Inf"
"1","  -2.215"
"1","  0.0687"
"1","
"
"1","
"
"1","Results are given on the log (not the response) scale. 
"
"1","P value adjustment: tukey method for comparing a family of 3 estimates 
"
"0","glmm_mod2 <- glmer(value ~ AI*Criteria + (1|Reviewer), data = statdf, family = poisson) #but is poisson legit? only one that works"
"0","summary(glmm_mod2)"
"1","Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
"
"1"," Family:"
"1"," "
"1","poisson"
"1"," "
"1"," ( log )"
"1","
"
"1","Formula:"
"1"," "
"1","value ~ AI * Criteria + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","statdf"
"1","
"
"1","
"
"1","     AIC "
"1","     BIC "
"1","  logLik "
"1","deviance "
"1","df.resid "
"1","
"
"1"," 19498.8 "
"1"," 19566.7 "
"1"," -9739.4 "
"1"," 19478.8 "
"1","    6521 "
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","     Min "
"1","      1Q "
"1","  Median "
"1","      3Q "
"1","     Max "
"1","
"
"1","-1.12972 "
"1","-0.33093 "
"1"," 0.09672 "
"1"," 0.35447 "
"1"," 0.98451 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.007003"
"1"," 0.08369 "
"1","
"
"1","Number of obs: 6531, groups: "
"1"," "
"1","Reviewer, 5"
"1","
"
"1","
Fixed effects:
"
"1","                                    "
"1"," Estimate"
"1"," Std. Error"
"1"," z value"
"1"," Pr(>|z|)"
"1","    "
"1","
(Intercept)                         "
"1","  0.88805"
"1","    0.04441"
"1","  19.998"
"1","  < 2e-16"
"1"," ***"
"1","
AIGPT4x1                            "
"1"," -0.22910"
"1","    0.03485"
"1","  -6.575"
"1"," 4.87e-11"
"1"," ***"
"1","
AIGPT4x3                            "
"1"," -0.15547"
"1","    0.03415"
"1","  -4.553"
"1"," 5.30e-06"
"1"," ***"
"1","
CriteriaContext to Question         "
"1","  0.02289"
"1","    0.03263"
"1","   0.701"
"1","    0.483"
"1","    "
"1","
CriteriaResponse to Context         "
"1","  0.05703"
"1","    0.03235"
"1","   1.763"
"1","    0.078"
"1"," .  "
"1","
AIGPT4x1:CriteriaContext to Question"
"1","  0.02915"
"1","    0.04880"
"1","   0.597"
"1","    0.550"
"1","    "
"1","
AIGPT4x3:CriteriaContext to Question"
"1","  0.01774"
"1","    0.04791"
"1","   0.370"
"1","    0.711"
"1","    "
"1","
AIGPT4x1:CriteriaResponse to Context"
"1","  0.05420"
"1","    0.04824"
"1","   1.124"
"1","    0.261"
"1","    "
"1","
AIGPT4x3:CriteriaResponse to Context"
"1","  0.03360"
"1","    0.04742"
"1","   0.709"
"1","    0.479"
"1","    "
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"1","
Correlation of Fixed Effects:
"
"1","           "
"1"," (Intr)"
"1"," AIGPT41"
"1"," AIGPT43"
"1"," CrtCtQ"
"1"," CrtRtC"
"1"," AIGPT41tQ"
"1"," AIGPT43tQ"
"1"," AIGPT41tC"
"1","
AIGPT4x1   "
"1"," -0.348"
"1","        "
"1","        "
"1","       "
"1","       "
"1","          "
"1","          "
"1","          "
"1","
AIGPT4x3   "
"1"," -0.355"
"1","  0.452 "
"1","        "
"1","       "
"1","       "
"1","          "
"1","          "
"1","          "
"1","
CrtrCntxttQ"
"1"," -0.372"
"1","  0.473 "
"1","  0.483 "
"1","       "
"1","       "
"1","          "
"1","          "
"1","          "
"1","
CrtrRspnstC"
"1"," -0.375"
"1","  0.477 "
"1","  0.487 "
"1","  0.510"
"1","       "
"1","          "
"1","          "
"1","          "
"1","
AIGPT41:CtQ"
"1","  0.248"
"1"," -0.714 "
"1"," -0.323 "
"1"," -0.668"
"1"," -0.341"
"1","          "
"1","          "
"1","          "
"1","
AIGPT43:CtQ"
"1","  0.253"
"1"," -0.322 "
"1"," -0.713 "
"1"," -0.681"
"1"," -0.347"
"1","  0.455   "
"1","          "
"1","          "
"1","
AIGPT41:CtC"
"1","  0.251"
"1"," -0.722 "
"1"," -0.327 "
"1"," -0.342"
"1"," -0.671"
"1","  0.516   "
"1","  0.233   "
"1","          "
"1","
AIGPT43:CtC"
"1","  0.256"
"1"," -0.326 "
"1"," -0.720 "
"1"," -0.348"
"1"," -0.682"
"1","  0.233   "
"1","  0.513   "
"1","  0.458   "
"1","
"
"0","anova(glmm_mod2)"
"1","Analysis of Variance Table"
"1","
"
"1","           "
"1"," npar"
"1","  Sum Sq"
"1"," Mean Sq"
"1"," F value"
"1","
AI         "
"1","    2"
"1"," 110.525"
"1","  55.262"
"1"," 55.2623"
"1","
Criteria   "
"1","    2"
"1","  18.435"
"1","   9.217"
"1","  9.2173"
"1","
AI:Criteria"
"1","    4"
"1","   1.310"
"1","   0.328"
"1","  0.3275"
"1","
"
"0","emm2 <- emmeans(glmm_mod2, ~ AI*Criteria)"
"0","contrasts2 <- pairs(emm2, adjust = ""tukey"")"
"0","print(contrasts2)"
"1",""
"1"," contrast                                                                   "
"1"," estimate"
"1","     SE"
"1","  df"
"1"," z.ratio"
"1"," p.value"
"1","
"
"1"," Elicit AI Response to Human Response - GPT4x1 AI Response to Human Response"
"1","  0.22910"
"1"," 0.0348"
"1"," Inf"
"1","   6.575"
"1","  <.0001"
"1","
"
"1"," Elicit AI Response to Human Response - GPT4x3 AI Response to Human Response"
"1","  0.15547"
"1"," 0.0342"
"1"," Inf"
"1","   4.553"
"1","  0.0002"
"1","
"
"1"," Elicit AI Response to Human Response - Elicit Context to Question          "
"1"," -0.02289"
"1"," 0.0326"
"1"," Inf"
"1","  -0.701"
"1","  0.9988"
"1","
"
"1"," Elicit AI Response to Human Response - GPT4x1 Context to Question          "
"1","  0.17706"
"1"," 0.0344"
"1"," Inf"
"1","   5.154"
"1","  <.0001"
"1","
"
"1"," Elicit AI Response to Human Response - GPT4x3 Context to Question          "
"1","  0.11485"
"1"," 0.0338"
"1"," Inf"
"1","   3.399"
"1","  0.0194"
"1","
"
"1"," Elicit AI Response to Human Response - Elicit Response to Context          "
"1"," -0.05703"
"1"," 0.0324"
"1"," Inf"
"1","  -1.763"
"1","  0.7071"
"1","
"
"1"," Elicit AI Response to Human Response - GPT4x1 Response to Context          "
"1","  0.11787"
"1"," 0.0338"
"1"," Inf"
"1","   3.486"
"1","  0.0145"
"1","
"
"1"," Elicit AI Response to Human Response - GPT4x3 Response to Context          "
"1","  0.06485"
"1"," 0.0333"
"1"," Inf"
"1","   1.945"
"1","  0.5823"
"1","
"
"1"," GPT4x1 AI Response to Human Response - GPT4x3 AI Response to Human Response"
"1"," -0.07362"
"1"," 0.0361"
"1"," Inf"
"1","  -2.039"
"1","  0.5159"
"1","
"
"1"," GPT4x1 AI Response to Human Response - Elicit Context to Question          "
"1"," -0.25198"
"1"," 0.0347"
"1"," Inf"
"1","  -7.268"
"1","  <.0001"
"1","
"
"1"," GPT4x1 AI Response to Human Response - GPT4x1 Context to Question          "
"1"," -0.05204"
"1"," 0.0363"
"1"," Inf"
"1","  -1.434"
"1","  0.8850"
"1","
"
"1"," GPT4x1 AI Response to Human Response - GPT4x3 Context to Question          "
"1"," -0.11425"
"1"," 0.0358"
"1"," Inf"
"1","  -3.195"
"1","  0.0377"
"1","
"
"1"," GPT4x1 AI Response to Human Response - Elicit Response to Context          "
"1"," -0.28613"
"1"," 0.0344"
"1"," Inf"
"1","  -8.314"
"1","  <.0001"
"1","
"
"1"," GPT4x1 AI Response to Human Response - GPT4x1 Response to Context          "
"1"," -0.11123"
"1"," 0.0358"
"1"," Inf"
"1","  -3.108"
"1","  0.0491"
"1","
"
"1"," GPT4x1 AI Response to Human Response - GPT4x3 Response to Context          "
"1"," -0.16425"
"1"," 0.0353"
"1"," Inf"
"1","  -4.646"
"1","  0.0001"
"1","
"
"1"," GPT4x3 AI Response to Human Response - Elicit Context to Question          "
"1"," -0.17836"
"1"," 0.0340"
"1"," Inf"
"1","  -5.250"
"1","  <.0001"
"1","
"
"1"," GPT4x3 AI Response to Human Response - GPT4x1 Context to Question          "
"1","  0.02159"
"1"," 0.0356"
"1"," Inf"
"1","   0.606"
"1","  0.9996"
"1","
"
"1"," GPT4x3 AI Response to Human Response - GPT4x3 Context to Question          "
"1"," -0.04063"
"1"," 0.0351"
"1"," Inf"
"1","  -1.158"
"1","  0.9650"
"1","
"
"1"," GPT4x3 AI Response to Human Response - Elicit Response to Context          "
"1"," -0.21250"
"1"," 0.0337"
"1"," Inf"
"1","  -6.303"
"1","  <.0001"
"1","
"
"1"," GPT4x3 AI Response to Human Response - GPT4x1 Response to Context          "
"1"," -0.03761"
"1"," 0.0351"
"1"," Inf"
"1","  -1.071"
"1","  0.9783"
"1","
"
"1"," GPT4x3 AI Response to Human Response - GPT4x3 Response to Context          "
"1"," -0.09062"
"1"," 0.0347"
"1"," Inf"
"1","  -2.614"
"1","  0.1804"
"1","
"
"1"," Elicit Context to Question - GPT4x1 Context to Question                    "
"1","  0.19995"
"1"," 0.0342"
"1"," Inf"
"1","   5.851"
"1","  <.0001"
"1","
"
"1"," Elicit Context to Question - GPT4x3 Context to Question                    "
"1","  0.13773"
"1"," 0.0336"
"1"," Inf"
"1","   4.099"
"1","  0.0014"
"1","
"
"1"," Elicit Context to Question - Elicit Response to Context                    "
"1"," -0.03414"
"1"," 0.0322"
"1"," Inf"
"1","  -1.061"
"1","  0.9795"
"1","
"
"1"," Elicit Context to Question - GPT4x1 Response to Context                    "
"1","  0.14075"
"1"," 0.0336"
"1"," Inf"
"1","   4.185"
"1","  0.0010"
"1","
"
"1"," Elicit Context to Question - GPT4x3 Response to Context                    "
"1","  0.08774"
"1"," 0.0332"
"1"," Inf"
"1","   2.646"
"1","  0.1679"
"1","
"
"1"," GPT4x1 Context to Question - GPT4x3 Context to Question                    "
"1"," -0.06221"
"1"," 0.0353"
"1"," Inf"
"1","  -1.763"
"1","  0.7065"
"1","
"
"1"," GPT4x1 Context to Question - Elicit Response to Context                    "
"1"," -0.23409"
"1"," 0.0339"
"1"," Inf"
"1","  -6.902"
"1","  <.0001"
"1","
"
"1"," GPT4x1 Context to Question - GPT4x1 Response to Context                    "
"1"," -0.05919"
"1"," 0.0353"
"1"," Inf"
"1","  -1.676"
"1","  0.7612"
"1","
"
"1"," GPT4x1 Context to Question - GPT4x3 Response to Context                    "
"1"," -0.11221"
"1"," 0.0349"
"1"," Inf"
"1","  -3.219"
"1","  0.0350"
"1","
"
"1"," GPT4x3 Context to Question - Elicit Response to Context                    "
"1"," -0.17187"
"1"," 0.0333"
"1"," Inf"
"1","  -5.155"
"1","  <.0001"
"1","
"
"1"," GPT4x3 Context to Question - GPT4x1 Response to Context                    "
"1","  0.00302"
"1"," 0.0348"
"1"," Inf"
"1","   0.087"
"1","  1.0000"
"1","
"
"1"," GPT4x3 Context to Question - GPT4x3 Response to Context                    "
"1"," -0.04999"
"1"," 0.0343"
"1"," Inf"
"1","  -1.457"
"1","  0.8751"
"1","
"
"1"," Elicit Response to Context - GPT4x1 Response to Context                    "
"1","  0.17490"
"1"," 0.0334"
"1"," Inf"
"1","   5.242"
"1","  <.0001"
"1","
"
"1"," Elicit Response to Context - GPT4x3 Response to Context                    "
"1","  0.12188"
"1"," 0.0329"
"1"," Inf"
"1","   3.705"
"1","  0.0066"
"1","
"
"1"," GPT4x1 Response to Context - GPT4x3 Response to Context                    "
"1"," -0.05302"
"1"," 0.0343"
"1"," Inf"
"1","  -1.544"
"1","  0.8345"
"1","
"
"1","
"
"1","Results are given on the log (not the response) scale. 
"
"1","P value adjustment: tukey method for comparing a family of 9 estimates 
"
"0","glmm_mod <- glmer(value ~ group_agent*AI + (1|Reviewer), data = statdf, family = poisson) #but is poisson legit? only one that works"
"0","summary(glmm_mod)"
"1","Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
"
"1"," Family:"
"1"," "
"1","poisson"
"1"," "
"1"," ( log )"
"1","
"
"1","Formula:"
"1"," "
"1","value ~ group_agent * AI + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","statdf"
"1","
"
"1","
"
"1","     AIC "
"1","     BIC "
"1","  logLik "
"1","deviance "
"1","df.resid "
"1","
"
"1"," 19505.9 "
"1"," 19553.4 "
"1"," -9745.9 "
"1"," 19491.9 "
"1","    6524 "
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","     Min "
"1","      1Q "
"1","  Median "
"1","      3Q "
"1","     Max "
"1","
"
"1","-1.11011 "
"1","-0.27208 "
"1"," 0.06722 "
"1"," 0.37846 "
"1"," 0.85393 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.00193 "
"1"," 0.04393 "
"1","
"
"1","Number of obs: 6531, groups: "
"1"," "
"1","Reviewer, 5"
"1","
"
"1","
Fixed effects:
"
"1","                                  "
"1"," Estimate"
"1"," Std. Error"
"1"," z value"
"1"," Pr(>|z|)"
"1","    "
"1","
(Intercept)                       "
"1","  1.05975"
"1","    0.04742"
"1","  22.347"
"1","  < 2e-16"
"1"," ***"
"1","
group_agentHuman Assessor         "
"1"," -0.19330"
"1","    0.05586"
"1","  -3.460"
"1","  0.00054"
"1"," ***"
"1","
AIGPT4x1                          "
"1"," -0.21606"
"1","    0.02672"
"1","  -8.086"
"1"," 6.18e-16"
"1"," ***"
"1","
AIGPT4x3                          "
"1"," -0.15665"
"1","    0.02629"
"1","  -5.958"
"1"," 2.55e-09"
"1"," ***"
"1","
group_agentHuman Assessor:AIGPT4x1"
"1","  0.03397"
"1","    0.03954"
"1","   0.859"
"1","  0.39027"
"1","    "
"1","
group_agentHuman Assessor:AIGPT4x3"
"1","  0.04089"
"1","    0.03887"
"1","   1.052"
"1","  0.29285"
"1","    "
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"1","
Correlation of Fixed Effects:
"
"1","            "
"1"," (Intr)"
"1"," grp_HA"
"1"," AIGPT41"
"1"," AIGPT43"
"1"," g_HA:AIGPT41"
"1","
grp_gntHmnA "
"1"," -0.849"
"1","       "
"1","        "
"1","        "
"1","             "
"1","
AIGPT4x1    "
"1"," -0.252"
"1","  0.214"
"1","        "
"1","        "
"1","             "
"1","
AIGPT4x3    "
"1"," -0.256"
"1","  0.217"
"1","  0.454 "
"1","        "
"1","             "
"1","
g_HA:AIGPT41"
"1","  0.170"
"1"," -0.319"
"1"," -0.676 "
"1"," -0.307 "
"1","             "
"1","
g_HA:AIGPT43"
"1","  0.173"
"1"," -0.325"
"1"," -0.307 "
"1"," -0.676 "
"1","  0.459      "
"1","
"
"0","anova(glmm_mod)"
"1","Analysis of Variance Table"
"1","
"
"1","              "
"1"," npar"
"1","  Sum Sq"
"1"," Mean Sq"
"1"," F value"
"1","
group_agent   "
"1","    1"
"1","  10.920"
"1","  10.920"
"1"," 10.9197"
"1","
AI            "
"1","    2"
"1"," 111.385"
"1","  55.693"
"1"," 55.6925"
"1","
group_agent:AI"
"1","    2"
"1","   1.286"
"1","   0.643"
"1","  0.6429"
"1","
"
"0","emm <- emmeans(glmm_mod, ~ group_agent*AI)"
"0","contrasts <- pairs(emm, adjust = ""tukey"")"
"0","print(contrasts)"
"1",""
"1"," contrast                                                   "
"1"," estimate"
"1","     SE"
"1","  df"
"1"," z.ratio"
"1"," p.value"
"1","
"
"1"," (GPT4-Turbo Assessor Elicit) - Human Assessor Elicit       "
"1","   0.1933"
"1"," 0.0559"
"1"," Inf"
"1","   3.460"
"1","  0.0071"
"1","
"
"1"," (GPT4-Turbo Assessor Elicit) - (GPT4-Turbo Assessor GPT4x1)"
"1","   0.2161"
"1"," 0.0267"
"1"," Inf"
"1","   8.086"
"1","  <.0001"
"1","
"
"1"," (GPT4-Turbo Assessor Elicit) - Human Assessor GPT4x1       "
"1","   0.3754"
"1"," 0.0565"
"1"," Inf"
"1","   6.638"
"1","  <.0001"
"1","
"
"1"," (GPT4-Turbo Assessor Elicit) - (GPT4-Turbo Assessor GPT4x3)"
"1","   0.1566"
"1"," 0.0263"
"1"," Inf"
"1","   5.958"
"1","  <.0001"
"1","
"
"1"," (GPT4-Turbo Assessor Elicit) - Human Assessor GPT4x3       "
"1","   0.3091"
"1"," 0.0563"
"1"," Inf"
"1","   5.491"
"1","  <.0001"
"1","
"
"1"," Human Assessor Elicit - (GPT4-Turbo Assessor GPT4x1)       "
"1","   0.0228"
"1"," 0.0565"
"1"," Inf"
"1","   0.403"
"1","  0.9986"
"1","
"
"1"," Human Assessor Elicit - Human Assessor GPT4x1              "
"1","   0.1821"
"1"," 0.0291"
"1"," Inf"
"1","   6.247"
"1","  <.0001"
"1","
"
"1"," Human Assessor Elicit - (GPT4-Turbo Assessor GPT4x3)       "
"1","  -0.0367"
"1"," 0.0563"
"1"," Inf"
"1","  -0.651"
"1","  0.9871"
"1","
"
"1"," Human Assessor Elicit - Human Assessor GPT4x3              "
"1","   0.1158"
"1"," 0.0286"
"1"," Inf"
"1","   4.043"
"1","  0.0007"
"1","
"
"1"," (GPT4-Turbo Assessor GPT4x1) - Human Assessor GPT4x1       "
"1","   0.1593"
"1"," 0.0572"
"1"," Inf"
"1","   2.785"
"1","  0.0599"
"1","
"
"1"," (GPT4-Turbo Assessor GPT4x1) - (GPT4-Turbo Assessor GPT4x3)"
"1","  -0.0594"
"1"," 0.0277"
"1"," Inf"
"1","  -2.145"
"1","  0.2640"
"1","
"
"1"," (GPT4-Turbo Assessor GPT4x1) - Human Assessor GPT4x3       "
"1","   0.0930"
"1"," 0.0570"
"1"," Inf"
"1","   1.633"
"1","  0.5767"
"1","
"
"1"," Human Assessor GPT4x1 - (GPT4-Turbo Assessor GPT4x3)       "
"1","  -0.2187"
"1"," 0.0570"
"1"," Inf"
"1","  -3.836"
"1","  0.0017"
"1","
"
"1"," Human Assessor GPT4x1 - Human Assessor GPT4x3              "
"1","  -0.0663"
"1"," 0.0299"
"1"," Inf"
"1","  -2.215"
"1","  0.2307"
"1","
"
"1"," (GPT4-Turbo Assessor GPT4x3) - Human Assessor GPT4x3       "
"1","   0.1524"
"1"," 0.0568"
"1"," Inf"
"1","   2.685"
"1","  0.0781"
"1","
"
"1","
"
"1","Results are given on the log (not the response) scale. 
"
"1","P value adjustment: tukey method for comparing a family of 6 estimates 
"
"0","mod_glmm <- glmer(value ~ AI*group_agent + (1|Reviewer), data = statdf, family = poisson)"
"0","summary(mod_glmm)"
"1","Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
"
"1"," Family:"
"1"," "
"1","poisson"
"1"," "
"1"," ( log )"
"1","
"
"1","Formula:"
"1"," "
"1","value ~ AI * group_agent + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","statdf"
"1","
"
"1","
"
"1","     AIC "
"1","     BIC "
"1","  logLik "
"1","deviance "
"1","df.resid "
"1","
"
"1"," 19505.9 "
"1"," 19553.4 "
"1"," -9745.9 "
"1"," 19491.9 "
"1","    6524 "
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","     Min "
"1","      1Q "
"1","  Median "
"1","      3Q "
"1","     Max "
"1","
"
"1","-1.11011 "
"1","-0.27208 "
"1"," 0.06722 "
"1"," 0.37846 "
"1"," 0.85393 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.00193 "
"1"," 0.04393 "
"1","
"
"1","Number of obs: 6531, groups: "
"1"," "
"1","Reviewer, 5"
"1","
"
"1","
Fixed effects:
"
"1","                                  "
"1"," Estimate"
"1"," Std. Error"
"1"," z value"
"1"," Pr(>|z|)"
"1","    "
"1","
(Intercept)                       "
"1","  1.05975"
"1","    0.04742"
"1","  22.346"
"1","  < 2e-16"
"1"," ***"
"1","
AIGPT4x1                          "
"1"," -0.21606"
"1","    0.02672"
"1","  -8.086"
"1"," 6.16e-16"
"1"," ***"
"1","
AIGPT4x3                          "
"1"," -0.15665"
"1","    0.02629"
"1","  -5.958"
"1"," 2.55e-09"
"1"," ***"
"1","
group_agentHuman Assessor         "
"1"," -0.19330"
"1","    0.05587"
"1","  -3.460"
"1","  0.00054"
"1"," ***"
"1","
AIGPT4x1:group_agentHuman Assessor"
"1","  0.03397"
"1","    0.03954"
"1","   0.859"
"1","  0.39027"
"1","    "
"1","
AIGPT4x3:group_agentHuman Assessor"
"1","  0.04089"
"1","    0.03887"
"1","   1.052"
"1","  0.29284"
"1","    "
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"1","
Correlation of Fixed Effects:
"
"1","           "
"1"," (Intr)"
"1"," AIGPT41"
"1"," AIGPT43"
"1"," grp_HA"
"1"," AIGPT41A"
"1","
AIGPT4x1   "
"1"," -0.252"
"1","        "
"1","        "
"1","       "
"1","         "
"1","
AIGPT4x3   "
"1"," -0.256"
"1","  0.454 "
"1","        "
"1","       "
"1","         "
"1","
grp_gntHmnA"
"1"," -0.849"
"1","  0.214 "
"1","  0.217 "
"1","       "
"1","         "
"1","
AIGPT41:_HA"
"1","  0.170"
"1"," -0.676 "
"1"," -0.307 "
"1"," -0.319"
"1","         "
"1","
AIGPT43:_HA"
"1","  0.173"
"1"," -0.307 "
"1"," -0.676 "
"1"," -0.325"
"1","  0.459  "
"1","
"
"0","anova(mod_glmm)"
"1","Analysis of Variance Table"
"1","
"
"1","              "
"1"," npar"
"1","  Sum Sq"
"1"," Mean Sq"
"1"," F value"
"1","
AI            "
"1","    2"
"1"," 111.550"
"1","  55.775"
"1"," 55.7752"
"1","
group_agent   "
"1","    1"
"1","  10.754"
"1","  10.754"
"1"," 10.7544"
"1","
AI:group_agent"
"1","    2"
"1","   1.286"
"1","   0.643"
"1","  0.6429"
"1","
"
"0","emm_glmm <- emmeans(mod_glmm, ~ AI|group_agent)"
"0","pairs(emm_glmm)"
"1","group_agent = GPT4-Turbo Assessor:
"
"1",""
"1"," contrast       "
"1"," estimate"
"1","     SE"
"1","  df"
"1"," z.ratio"
"1"," p.value"
"1","
"
"1"," Elicit - GPT4x1"
"1","   0.2161"
"1"," 0.0267"
"1"," Inf"
"1","   8.086"
"1","  <.0001"
"1","
"
"1"," Elicit - GPT4x3"
"1","   0.1566"
"1"," 0.0263"
"1"," Inf"
"1","   5.958"
"1","  <.0001"
"1","
"
"1"," GPT4x1 - GPT4x3"
"1","  -0.0594"
"1"," 0.0277"
"1"," Inf"
"1","  -2.145"
"1","  0.0809"
"1","
"
"1","
"
"1","group_agent = Human Assessor:
"
"1",""
"1"," contrast       "
"1"," estimate"
"1","     SE"
"1","  df"
"1"," z.ratio"
"1"," p.value"
"1","
"
"1"," Elicit - GPT4x1"
"1","   0.1821"
"1"," 0.0291"
"1"," Inf"
"1","   6.247"
"1","  <.0001"
"1","
"
"1"," Elicit - GPT4x3"
"1","   0.1158"
"1"," 0.0286"
"1"," Inf"
"1","   4.043"
"1","  0.0002"
"1","
"
"1"," GPT4x1 - GPT4x3"
"1","  -0.0663"
"1"," 0.0299"
"1"," Inf"
"1","  -2.215"
"1","  0.0687"
"1","
"
"1","
"
"1","Results are given on the log (not the response) scale. 
"
"1","P value adjustment: tukey method for comparing a family of 3 estimates 
"
"0","emm_int_glmm <- emmeans(mod_glmm, pairwise ~ AI:group_agent)"
"0","pairs(emm_int_glmm)"
"1",""
"1"," contrast                                                   "
"1"," estimate"
"1","     SE"
"1","  df"
"1"," z.ratio"
"1"," p.value"
"1","
"
"1"," (Elicit GPT4-Turbo Assessor) - (GPT4x1 GPT4-Turbo Assessor)"
"1","   0.2161"
"1"," 0.0267"
"1"," Inf"
"1","   8.086"
"1","  <.0001"
"1","
"
"1"," (Elicit GPT4-Turbo Assessor) - (GPT4x3 GPT4-Turbo Assessor)"
"1","   0.1566"
"1"," 0.0263"
"1"," Inf"
"1","   5.958"
"1","  <.0001"
"1","
"
"1"," (Elicit GPT4-Turbo Assessor) - Elicit Human Assessor       "
"1","   0.1933"
"1"," 0.0559"
"1"," Inf"
"1","   3.460"
"1","  0.0071"
"1","
"
"1"," (Elicit GPT4-Turbo Assessor) - GPT4x1 Human Assessor       "
"1","   0.3754"
"1"," 0.0566"
"1"," Inf"
"1","   6.638"
"1","  <.0001"
"1","
"
"1"," (Elicit GPT4-Turbo Assessor) - GPT4x3 Human Assessor       "
"1","   0.3091"
"1"," 0.0563"
"1"," Inf"
"1","   5.491"
"1","  <.0001"
"1","
"
"1"," (GPT4x1 GPT4-Turbo Assessor) - (GPT4x3 GPT4-Turbo Assessor)"
"1","  -0.0594"
"1"," 0.0277"
"1"," Inf"
"1","  -2.145"
"1","  0.2640"
"1","
"
"1"," (GPT4x1 GPT4-Turbo Assessor) - Elicit Human Assessor       "
"1","  -0.0228"
"1"," 0.0565"
"1"," Inf"
"1","  -0.403"
"1","  0.9986"
"1","
"
"1"," (GPT4x1 GPT4-Turbo Assessor) - GPT4x1 Human Assessor       "
"1","   0.1593"
"1"," 0.0572"
"1"," Inf"
"1","   2.785"
"1","  0.0599"
"1","
"
"1"," (GPT4x1 GPT4-Turbo Assessor) - GPT4x3 Human Assessor       "
"1","   0.0930"
"1"," 0.0570"
"1"," Inf"
"1","   1.633"
"1","  0.5767"
"1","
"
"1"," (GPT4x3 GPT4-Turbo Assessor) - Elicit Human Assessor       "
"1","   0.0367"
"1"," 0.0563"
"1"," Inf"
"1","   0.651"
"1","  0.9871"
"1","
"
"1"," (GPT4x3 GPT4-Turbo Assessor) - GPT4x1 Human Assessor       "
"1","   0.2187"
"1"," 0.0570"
"1"," Inf"
"1","   3.836"
"1","  0.0017"
"1","
"
"1"," (GPT4x3 GPT4-Turbo Assessor) - GPT4x3 Human Assessor       "
"1","   0.1524"
"1"," 0.0568"
"1"," Inf"
"1","   2.685"
"1","  0.0781"
"1","
"
"1"," Elicit Human Assessor - GPT4x1 Human Assessor              "
"1","   0.1821"
"1"," 0.0291"
"1"," Inf"
"1","   6.247"
"1","  <.0001"
"1","
"
"1"," Elicit Human Assessor - GPT4x3 Human Assessor              "
"1","   0.1158"
"1"," 0.0286"
"1"," Inf"
"1","   4.043"
"1","  0.0007"
"1","
"
"1"," GPT4x1 Human Assessor - GPT4x3 Human Assessor              "
"1","  -0.0663"
"1"," 0.0299"
"1"," Inf"
"1","  -2.215"
"1","  0.2307"
"1","
"
"1","
"
"1","Results are given on the log (not the response) scale. 
"
"1","P value adjustment: tukey method for comparing a family of 6 estimates 
"
"0","# comparing full model with interaction to reduced model without - if p < 0.05, then interaction between AI and group_agent is sig."
"0","mod_red <- glmer(value ~ AI + group_agent + (1|Reviewer), data = statdf, family = poisson)"
"0","anova_res <- anova(mod_red, mod_glmm)"
"0","print(anova_res)"
"1","Data: statdf"
"1","
"
"1","Models:"
"1","
"
"1","mod_red: value ~ AI + group_agent + (1 | Reviewer)"
"1","
"
"1","mod_glmm: value ~ AI * group_agent + (1 | Reviewer)"
"1","
"
"1","        "
"1"," npar"
"1","   AIC"
"1","   BIC"
"1","  logLik"
"1"," deviance"
"1","  Chisq"
"1"," Df"
"1"," Pr(>Chisq)"
"1","
mod_red "
"1","    5"
"1"," 19503"
"1"," 19537"
"1"," -9746.6"
"1","    19493"
"1","       "
"1","   "
"1","           "
"1","
mod_glmm"
"1","    7"
"1"," 19506"
"1"," 19553"
"1"," -9745.9"
"1","    19492"
"1"," 1.2861"
"1","  2"
"1","     0.5257"
"1","
"
"0","#### secondary analysis ####"
"0","statdfx <- statdf %>% filter(Agent == ""Human"")"
"0","xx <- glmer(value ~ AI + (1|Reviewer), family = poisson, data = filter(statdfx, Criteria == ""AI Response to Human Response""))"
"0",""
"0","#only comparing the value to the intercept with reviewer as the random effect "
"0","attempt1 <- lmer(value ~ 1 + (1|Reviewer), data = filter(statdfx, Criteria == ""AI Response to Human Response""))"
"0","summary(attempt1)"
"1","Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
"
"1","Formula:"
"1"," "
"1","value ~ 1 + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","filter(statdfx, Criteria == ""AI Response to Human Response"")"
"1","
"
"1","
"
"1","REML criterion at convergence:"
"1"," "
"1","2531.7"
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","    Min "
"1","     1Q "
"1"," Median "
"1","     3Q "
"1","    Max "
"1","
"
"1","-1.8685 "
"1","-0.9853 "
"1"," 0.1453 "
"1"," 0.7353 "
"1"," 1.6185 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.08848 "
"1"," 0.2975  "
"1","
"
"1"," Residual"
"1","            "
"1"," 0.58999 "
"1"," 0.7681  "
"1","
"
"1","Number of obs: 1089, groups: "
"1"," "
"1","Reviewer, 4"
"1","
"
"1","
Fixed effects:
"
"1","           "
"1"," Estimate"
"1"," Std. Error"
"1","     df"
"1"," t value"
"1"," Pr(>|t|)"
"1","    "
"1","
(Intercept)"
"1","   2.0244"
"1","     0.1506"
"1"," 3.0115"
"1","   13.44"
"1"," 0.000873"
"1"," ***"
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"0","randoms <- ranef(attempt1, condVar = TRUE) #determining intercepts"
"0",""
"0","#comparing the value by each AI (reviewer still random)"
"0","attempt2 <- lmer(value ~ AI + (1|Reviewer), data = filter(statdfx, Criteria == ""AI Response to Human Response""))"
"0","summary(attempt2)"
"1","Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
"
"1","Formula:"
"1"," "
"1","value ~ AI + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","filter(statdfx, Criteria == ""AI Response to Human Response"")"
"1","
"
"1","
"
"1","REML criterion at convergence:"
"1"," "
"1","2476.1"
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","     Min "
"1","      1Q "
"1","  Median "
"1","      3Q "
"1","     Max "
"1","
"
"1","-2.24667 "
"1","-0.91910 "
"1"," 0.03013 "
"1"," 0.80874 "
"1"," 1.93627 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.08858 "
"1"," 0.2976  "
"1","
"
"1"," Residual"
"1","            "
"1"," 0.55733 "
"1"," 0.7465  "
"1","
"
"1","Number of obs: 1089, groups: "
"1"," "
"1","Reviewer, 4"
"1","
"
"1","
Fixed effects:
"
"1","           "
"1","   Estimate"
"1"," Std. Error"
"1","         df"
"1"," t value"
"1"," Pr(>|t|)"
"1","    "
"1","
(Intercept)"
"1","    2.26586"
"1","    0.15394"
"1","    3.28881"
"1","  14.719"
"1"," 0.000409"
"1"," ***"
"1","
AIGPT4x1   "
"1","   -0.44353"
"1","    0.05541"
"1"," 1083.01097"
"1","  -8.004"
"1"," 3.09e-15"
"1"," ***"
"1","
AIGPT4x3   "
"1","   -0.28099"
"1","    0.05541"
"1"," 1083.01097"
"1","  -5.071"
"1"," 4.66e-07"
"1"," ***"
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"1","
Correlation of Fixed Effects:
"
"1","        "
"1"," (Intr)"
"1"," AIGPT41"
"1","
AIGPT4x1"
"1"," -0.180"
"1","        "
"1","
AIGPT4x3"
"1"," -0.180"
"1","  0.500 "
"1","
"
"0","att2 <- emmeans(attempt2, ~ AI)"
"0","contrasts <- pairs(att2, adjust = ""tukey"")"
"0","print(contrasts)"
"1",""
"1"," contrast       "
"1"," estimate"
"1","     SE"
"1","   df"
"1"," t.ratio"
"1"," p.value"
"1","
"
"1"," Elicit - GPT4x1"
"1","    0.444"
"1"," 0.0554"
"1"," 1083"
"1","   8.004"
"1","  <.0001"
"1","
"
"1"," Elicit - GPT4x3"
"1","    0.281"
"1"," 0.0554"
"1"," 1083"
"1","   5.071"
"1","  <.0001"
"1","
"
"1"," GPT4x1 - GPT4x3"
"1","   -0.163"
"1"," 0.0554"
"1"," 1083"
"1","  -2.933"
"1","  0.0096"
"1","
"
"1","
"
"1","Degrees-of-freedom method: kenward-roger 
"
"1","P value adjustment: tukey method for comparing a family of 3 estimates 
"
"0","#anova comparing the two models"
"0","anova(attempt1, attempt2) #AIC lower for attempt 2, better, meaning AI has an effect"
"2","refitting model(s) with ML (instead of REML)
"
"1","Data: filter(statdfx, Criteria == ""AI Response to Human Response"")"
"1","
"
"1","Models:"
"1","
"
"1","attempt1: value ~ 1 + (1 | Reviewer)"
"1","
"
"1","attempt2: value ~ AI + (1 | Reviewer)"
"1","
"
"1","        "
"1"," npar"
"1","    AIC"
"1","    BIC"
"1","  logLik"
"1"," deviance"
"1","  Chisq"
"1"," Df"
"1"," Pr(>Chisq)"
"1","    "
"1","
attempt1"
"1","    3"
"1"," 2535.6"
"1"," 2550.5"
"1"," -1264.8"
"1","   2529.6"
"1","       "
"1","   "
"1","           "
"1","    "
"1","
attempt2"
"1","    5"
"1"," 2475.8"
"1"," 2500.7"
"1"," -1232.9"
"1","   2465.8"
"1"," 63.795"
"1","  2"
"1","  1.403e-14"
"1"," ***"
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"0","#now including question as a random effect"
"0","attempt3 <- lmer(value ~ AI + (1|Question) + (1|Reviewer), data = filter(statdfx, Criteria == ""AI Response to Human Response""))"
"0","anova(attempt2, attempt3)"
"2","refitting model(s) with ML (instead of REML)
"
"1","Data: filter(statdfx, Criteria == ""AI Response to Human Response"")"
"1","
"
"1","Models:"
"1","
"
"1","attempt2: value ~ AI + (1 | Reviewer)"
"1","
"
"1","attempt3: value ~ AI + (1 | Question) + (1 | Reviewer)"
"1","
"
"1","        "
"1"," npar"
"1","    AIC"
"1","    BIC"
"1","  logLik"
"1"," deviance"
"1","  Chisq"
"1"," Df"
"1"," Pr(>Chisq)"
"1","    "
"1","
attempt2"
"1","    5"
"1"," 2475.8"
"1"," 2500.7"
"1"," -1232.9"
"1","   2465.8"
"1","       "
"1","   "
"1","           "
"1","    "
"1","
attempt3"
"1","    6"
"1"," 2383.7"
"1"," 2413.6"
"1"," -1185.8"
"1","   2371.7"
"1"," 94.116"
"1","  1"
"1","  < 2.2e-16"
"1"," ***"
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"0","summary(attempt3)"
"1","Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
"
"1","Formula:"
"1"," "
"1","value ~ AI + (1 | Question) + (1 | Reviewer)"
"1","
"
"1","   Data:"
"1"," "
"1","filter(statdfx, Criteria == ""AI Response to Human Response"")"
"1","
"
"1","
"
"1","REML criterion at convergence:"
"1"," "
"1","2382.1"
"1","
"
"1","
"
"1","Scaled residuals:"
"1"," "
"1","
"
"1","    Min "
"1","     1Q "
"1"," Median "
"1","     3Q "
"1","    Max "
"1","
"
"1","-2.5227 "
"1","-0.8730 "
"1"," 0.2236 "
"1"," 0.7298 "
"1"," 2.2621 "
"1","
"
"1","
"
"1","Random effects:
"
"1",""
"1"," Groups  "
"1"," Name       "
"1"," Variance"
"1"," Std.Dev."
"1","
"
"1"," Question"
"1"," (Intercept)"
"1"," 0.08621 "
"1"," 0.2936  "
"1","
"
"1"," Reviewer"
"1"," (Intercept)"
"1"," 0.06150 "
"1"," 0.2480  "
"1","
"
"1"," Residual"
"1","            "
"1"," 0.50148 "
"1"," 0.7081  "
"1","
"
"1","Number of obs: 1089, groups: "
"1"," "
"1","Question, 11; Reviewer, 4"
"1","
"
"1","
Fixed effects:
"
"1","           "
"1","   Estimate"
"1"," Std. Error"
"1","         df"
"1"," t value"
"1"," Pr(>|t|)"
"1","    "
"1","
(Intercept)"
"1","    2.27065"
"1","    0.15732"
"1","    3.37620"
"1","  14.434"
"1"," 0.000375"
"1"," ***"
"1","
AIGPT4x1   "
"1","   -0.44353"
"1","    0.05256"
"1"," 1076.00003"
"1","  -8.438"
"1","  < 2e-16"
"1"," ***"
"1","
AIGPT4x3   "
"1","   -0.28099"
"1","    0.05256"
"1"," 1076.00003"
"1","  -5.346"
"1","  1.1e-07"
"1"," ***"
"1","
"
"1","---
Signif. codes:  "
"1",""
"1","0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
"1","
"
"1","
Correlation of Fixed Effects:
"
"1","        "
"1"," (Intr)"
"1"," AIGPT41"
"1","
AIGPT4x1"
"1"," -0.167"
"1","        "
"1","
AIGPT4x3"
"1"," -0.167"
"1","  0.500 "
"1","
"
"0","#### PROPER MODEL TESTS ####"
"0","statdfx <- statdf %>% filter(Agent == ""Human"") #only investigating human assessors (no group agent)"
"0",""
"0","#comparing distribution of values to the mean of 2"
"0","statdfx %>% group_by(AI, Criteria) %>% summarise(t_value = t.test(value, mu = 2, alternative = ""less"")$statistic)"
"2","`summarise()` has grouped output by 'AI'. You can override using the `.groups` argument."
